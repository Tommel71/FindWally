{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b18e8a7f-89de-4e74-a081-f1457ab7eba8",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7ac80f87",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Tom\\.conda\\envs\\tensorflow_gpu\\lib\\site-packages\\scipy\\__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.1\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "from fastai.vision.all import *\n",
    "import os\n",
    "import pandas as pd\n",
    "import zipfile\n",
    "import os\n",
    "import pandas as pd\n",
    "from torchvision.io import read_image\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import DataLoader\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c712d5ab",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "# Import files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5e678eba-b9bb-4ad8-80cc-e45b05cd299a",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "202599"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files = get_image_files(\"lumos_datathon/archive/img_align_celeba\")\n",
    "len(files)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b317fe64",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "# Exclude evaluation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8c0b914d-91c3-449c-9706-47920b8c634e",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "f_eval = pd.read_csv(\"eval_data_public.csv\")\n",
    "df_train = pd.read_csv(\"train_data.csv\")\n",
    "df_att = pd.read_csv(\"list_attr_celeba.csv\").set_index(\"image_id\")\n",
    "df_att = df_att.replace({-1:0})\n",
    "columns = df_att.columns\n",
    "\n",
    "def get_labels(row):\n",
    "    return \",\".join(list(columns[row]))\n",
    "\n",
    "\n",
    "df_eval = pd.read_csv(\"eval_data_public.csv\")\n",
    "s_eval = df_eval.set_index(\"id\")[\"16_image_ids\"]\n",
    "df_train = df_train.set_index(\"id\")[[\"16_image_ids\",\"anomalous_image_id\",\"attributes\"]]\n",
    "for col in columns:\n",
    "    df_att[col] = df_att[col].apply(bool)\n",
    "    \n",
    "eval_set = set()\n",
    "for idx in range(len(df_eval)):\n",
    "    ids = df_eval.iloc[idx][\"16_image_ids\"].split(\" \")\n",
    "    eval_set = set.union(set(ids))\n",
    "    \n",
    "train_labels = list(set(df_att.index).difference(eval_set))\n",
    "val_labels = list(eval_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc33f358",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "# Define ImageDataLoaders for fast ai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4db99720-08cd-4b7c-865f-2298669e8aa4",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Due to IPython and Windows limitation, python multiprocessing isn't available now.\n",
      "So `number_workers` is changed to 0 to avoid getting stuck\n",
      "Due to IPython and Windows limitation, python multiprocessing isn't available now.\n",
      "So `number_workers` is changed to 0 to avoid getting stuck\n"
     ]
    }
   ],
   "source": [
    "all_label_list = list(df_att.apply(get_labels,axis=1))\n",
    "train_label_list = list(df_att.loc[train_labels].apply(get_labels,axis=1))\n",
    "val_label_list = list(df_att.loc[val_labels].apply(get_labels,axis=1))\n",
    "\n",
    "path = \"lumos_datathon/archive/img_align_celeba\"\n",
    "df_train2 = pd.DataFrame.from_dict({\"name\": train_labels, \"labels\": train_label_list})\n",
    "train_dls = ImageDataLoaders.from_df(df_train2, path,label_delim=\",\")\n",
    "\n",
    "full_df = pd.DataFrame.from_dict({\"name\": list(df_att.index), \"labels\": all_label_list})\n",
    "full_dls = ImageDataLoaders.from_df(full_df, path,label_delim=\",\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b958932",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "# Define Metrics and finetune the resnet34"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87a34855-c4c3-4835-8eeb-2bede519dc1e",
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Tom\\AppData\\Roaming\\Python\\Python38\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and will be removed in 0.15, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Tom\\AppData\\Roaming\\Python\\Python38\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=ResNet34_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet34_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      <progress value='0' class='' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      0.00% [0/1 00:00&lt;?]\n",
       "    </div>\n",
       "    \n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy_multi</th>\n",
       "      <th>F1(macro)</th>\n",
       "      <th>F1(samples)</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>\n",
       "\n",
       "    <div>\n",
       "      <progress value='1958' class='' max='2532' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      77.33% [1958/2532 20:51&lt;06:06 0.2561]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "f1_macro = F1ScoreMulti(thresh=0.5, average='macro')\n",
    "f1_macro.name = 'F1(macro)'\n",
    "f1_samples = F1ScoreMulti(thresh=0.5, average='samples')\n",
    "f1_samples.name = 'F1(samples)'\n",
    "learn = vision_learner(train_dls, resnet34, metrics=[partial(accuracy_multi, thresh=0.5) ,f1_macro,  f1_samples])\n",
    "\n",
    "# learn.lr_find()\n",
    "learn.fine_tune(1, 0.003) # TODO change to 6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "216b36d4",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f37b54ba-74bc-4f0e-b414-55276f6551ec",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "interp = Interpretation.from_learner(learn)\n",
    "interp.plot_top_losses(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c09eaa63",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "# Export model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f093e4e4-2209-4d22-b84f-4173eba50c81",
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "learn.export(f\"{os.getcwd()}/learners/multi_model_no_eval.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1fce4f6",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c639a2ba-3271-42e1-8805-ba01c25f6b8d",
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "dl = learn.dls.test_dl(files)\n",
    "dl.show_batch()\n",
    "preds = learn.get_preds(dl=dl)\n",
    "preds = preds[0]\n",
    "preds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b883907",
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "source": [
    "# Save predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a827b0d5-995c-43f5-99a1-31b2fdea450c",
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "with open('tensorpreds_all_no_eval.pkl', 'wb') as handle:\n",
    "    pickle.dump(preds, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "series_preds = pd.DataFrame.from_dict({\"name\":list(df_att.index),\"preds\":list(preds)}).set_index(\"name\")[\"preds\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d5cda2b-9197-4599-87e9-7a731fe48bfc",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Pytorch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87d402a5-f07b-43f9-b284-4b01d01eae32",
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9bf2fb4-ee4e-4553-900f-17592d30afc7",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Define the dataset and create dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e177c691-416f-43b9-a0e1-ed49591363df",
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using {device} device\")\n",
    "\n",
    "def get_tensor_from_traindf(row):\n",
    "    return torch.tensor(np.array([xid == row[\"anomalous_image_id\"] for xid in row[\"16_image_ids\"].split(\" \")]).astype(float))\n",
    "target_series = df_train.apply(get_tensor_from_traindf,axis=1)\n",
    "df_train[\"target_series\"]=target_series\n",
    "\n",
    "\n",
    "learning_rate = 1e-3\n",
    "batch_size = 64\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, series_preds, df_train):\n",
    "        self.series_preds = series_preds\n",
    "        self.df_train= df_train\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df_train)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df_train.iloc[idx]\n",
    "        image_ids = row[\"16_image_ids\"].split(\" \")\n",
    "        target = row[\"target_series\"]\n",
    "        inp = torch.tensor(np.concatenate(self.series_preds.loc[image_ids]))\n",
    "        return inp, target\n",
    "\n",
    "\n",
    "# MAX_LEN = 10000\n",
    "MAX_LEN = 157692\n",
    "arr = np.arange(MAX_LEN)\n",
    "np.random.shuffle(arr)\n",
    "train_idx, val_idx = arr[:int(MAX_LEN*0.95)],arr[int(MAX_LEN*0.95):MAX_LEN]\n",
    "train_dataset = CustomDataset(series_preds=series_preds,df_train=df_train.iloc[train_idx])\n",
    "val_dataset = CustomDataset(series_preds=series_preds,df_train=df_train.iloc[val_idx])\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4681d807-cedd-4210-a9df-b3add3051a94",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Define training and evaluation \n",
    "\n",
    "### of Neural Network that takes in label probabilities of 16 images and predicts the anomaly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4e417ec-68c0-47d8-ba1d-eb3499d8bdc2",
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(16*40, 320),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(320, 160),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(160, 16),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits\n",
    "\n",
    "model = NeuralNetwork().to(device)\n",
    "    \n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)\n",
    "    \n",
    "def train_loop(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        X=X.to(device)\n",
    "        y=y.to(device)\n",
    "        # Compute prediction and loss\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch % 100 == 0:\n",
    "            loss, current = loss.item(), batch * len(X)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
    "            \n",
    "def test_loop(dataloader, model, loss_fn):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    test_loss, correct = 0, 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            X=X.to(device)\n",
    "            y=y.to(device)\n",
    "            pred = model(X)\n",
    "            # print(pred.argmax(1))\n",
    "            # print(y.argmax(1))\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y.argmax(1)).type(torch.float).sum().item()\n",
    "\n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cddbe266",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b07220b0-710c-4d48-8688-4dc21e3f045d",
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "epochs = 1\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train_loop(train_dataloader, model, loss_fn, optimizer)\n",
    "    test_loop(val_dataloader, model, loss_fn)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6945b73c",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "# Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "229375b0-beba-4a95-9798-f3ce3ceeb1d4",
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "torch.save(model,\"models/ep9_noleak.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fe74475-96c3-4274-b6ff-8d409ee33f77",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    },
    "tags": []
   },
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abb365c7-9238-47ff-8f42-303bd0069f6c",
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "tensors=[]\n",
    "for idx in range(len(df_eval)):\n",
    "    row = df_eval.iloc[idx]\n",
    "    image_ids = row[\"16_image_ids\"].split(\" \")\n",
    "    inp = torch.tensor(np.concatenate(series_preds.loc[image_ids])).reshape((1,640))\n",
    "    tensors.append(inp)\n",
    "    \n",
    "tensors = torch.cat(tensors,dim=0)\n",
    "tensors = tensors.to(device)\n",
    "with torch.no_grad():\n",
    "    eval_preds = model(tensors)\n",
    "eval_label_list = list(eval_preds.argmax(1))\n",
    "eval_label_list = [x.item() for x in eval_label_list]\n",
    "result_df = pd.DataFrame.from_dict({\"id\":list(df_eval.index),\"anomalous_image_index\":eval_label_list})\n",
    "result_df = result_df.set_index(\"id\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "085baca6",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "# Save dataframe ready for submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "173963d4-648d-4b8f-a381-e529fe378e80",
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "result_df.to_csv(\"result_csvs/ep9_noleak.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "791a7f22-8d37-41fc-86be-3c1752b99129",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Misc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c45e3dab-d6d8-4810-aead-8a9a6389ef50",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Testing how many labels are in df_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "871707f6-1aa0-42b4-982c-3371a3436dbf",
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df_eval"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2a9c09f-3370-4d41-8e78-f27f9039a5c0",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Unzipping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a077bcb-4971-4737-b464-b0c8d7db6703",
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "with zipfile.ZipFile(\"lumos-datathon.zip\", 'r') as zip_ref:\n",
    "    zip_ref.extractall(\"lumos_datathon\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}